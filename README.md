# Offline-Chatbot

A fully offline, intelligent chatbot built using Flask, Ollama, and HTML/CSS/JS. This chatbot provides a ChatGPT-like experience completely offline with multiple model support.

## ğŸš€ Key Features

- ğŸ’¬ Interactive chat with multiple AI model support
- ğŸ¤– Support for any Ollama model (Mistral, Llama, CodeLlama, etc.)
- ğŸ“ File understanding (PDF, TXT support)
- ğŸ™ï¸ Voice input through browser
- ğŸ¨ Modern, responsive UI
- ğŸ”’ 100% offline operation - no API keys needed

## ğŸ“‹ Detailed Features

### ğŸ§  Multi-Model Support
- Choose from any installed Ollama model
- Switch models during conversation
- Refresh model list with one click
- Automatic model detection

### ğŸ“ File Upload Support
- **Supported Formats:**
  - PDF (.pdf)
  - Text files (.txt)
- **Features:**
  - Automatic content extraction
  - Context-aware responses about uploaded files
  - Error handling for unsupported formats
  - File content size optimization

### ğŸ™ï¸ Voice Input
- Browser-based speech recognition
- Real-time speech-to-text conversion
- Automatic query submission
- Multiple language support (browser-dependent)

### ğŸ’» User Interface
- Clean, modern design
- Real-time response streaming
- Mobile-responsive layout
- Easy model switching
- File upload progress indication
- Clear message history

## ğŸ› ï¸ Installation Guide

### 1ï¸âƒ£ Install Python
1. Download Python 3.10 or newer from [python.org](https://www.python.org/downloads/)
2. During installation:
   - âœ… Check "Add Python to PATH"
   - âœ… Check "Install pip"
3. Verify installation:
   ```bash
   python --version
   ```

### 2ï¸âƒ£ Install Ollama
1. Download Ollama from [Ollama](https://ollama.com/download)
2. Install and start Ollama
3. Install at least one model:
   ```bash
   # Install Mistral (recommended starter model)
   ollama pull mistral

   # Optional: Install additional models
   ollama pull llama2
   ollama pull codellama
   ```

### 3ï¸âƒ£ Setup Project
1. Clone or download the project:
   ```bash
   git clone https://github.com/shannu-afk/offline_chatbot.git
   cd offline_chatbot
   ```

2. Install Python dependencies:
   ```bash
   pip install -r requirements.txt
   ```

### 4ï¸âƒ£ Run the Chatbot
1. Make sure Ollama is running in background
2. Start the Flask server:
   ```bash
   python app.py
   ```
3. Open your browser and go to:
   ```
   http://127.0.0.1:5000
   ```

## ğŸ’¡ Usage Guide

### Chatting
1. Select your preferred model from the dropdown
2. Type your message and press Send
3. Or click ğŸ¤ for voice input

### File Upload
1. Click "Choose File" button
2. Select a PDF or TXT file
3. Wait for upload confirmation
4. Reference the file in your chat

### Model Switching
1. Use the model dropdown to see available models
2. Click ğŸ”„ to refresh the model list
3. Select a different model anytime
4. Each message will use the currently selected model

## ğŸ”§ Troubleshooting

### Common Issues:
1. **"Error communicating with model"**
   - Ensure Ollama is running
   - Check if selected model is installed
   - Try refreshing the model list

2. **"Speech recognition not supported"**
   - Use a modern browser (Chrome recommended)
   - Allow microphone permissions

3. **File Upload Issues**
   - Check file format (PDF/TXT only)
   - Ensure file isn't corrupted
   - Try with a smaller file if too large

## ğŸ“¦ Dependencies

### Backend
- Flask==3.0.2
- requests==2.31.0
- PyPDF2==3.0.1

### Frontend
- Modern web browser with:
  - JavaScript enabled
  - Web Speech API support
  - WebSocket support

### External
- Ollama (with at least one model installed)

## ğŸ‘¤ Author

**Kodali Shanmukh Chowdary**
- ğŸ“§ Email: kodalishanmukh6thfinger@gmail.com
- ğŸ“ B.Tech AI & ML
- ğŸŒ Location: India

## ğŸ“„ License

This project is open source and available under the MIT License.

## ğŸ¤ Contributing

Contributions, issues, and feature requests are welcome!